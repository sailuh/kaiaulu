# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at https://mozilla.org/MPL/2.0/.

#' Parse gitlog from Perceval
#'
#' @param perceval_path path to perceval binary
#' @param git_repo_path path to git repo (ends in .git)
#' @param save_path optional save path for .rds object
#' @param from_date a string of the form "YYYY-MM-DD"
#' @param to_date a string of the form "YYYY-MM-DD"
#' @export
#' @family parsers
parse_gitlog <- function(perceval_path,git_repo_path,save_path=NA,perl_regex=NA){
  data.files <- data.Author <- data.AuthorDate <- data.commit <- data.Commit <- data.CommitDate <- data.message <- NULL # due to NSE notes in R CMD check
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  perceval_path <- path.expand(perceval_path)
  git_repo_path <- path.expand(git_repo_path)
  git_uri <-  git_repo_path
  save_path <- ifelse(!is.na(save_path),path.expand(save_path),NA)

  # Use percerval to parse .git --json line is required to be parsed by jsonlite::fromJSON.
  # The log will be saved to the /tmp/ folder
  gitlog_path <- "/tmp/gitlog.log"

  # Perceval suggested flags
  perceval_flags <-
    c(
      '--raw',
      '--numstat',
      '--pretty=fuller',
      '--decorate=full',
      '--parents',
      '--reverse',
      '--topo-order',
      '-M',
      '-C',
      '-c',
      '--remotes=origin'
    )
  # Execute shell command to extract gitlog using Percerval recommended format (See it's README.md.
  if(!is.na(perl_regex)){
    gitlog_call_message <- system2("git",
                                   args = c('--git-dir',
                                            git_repo_path,
                                            'log',
                                            '--no-merges',
                                            'master',
                                            stri_c('--grep=','"',perl_regex,'"'),
                                            '--perl-regexp',
                                            perceval_flags,
                                            #'--all',
                                            '>' ,
                                            gitlog_path),
                                   stdout = TRUE,
                                   stderr = FALSE)
  }else{
    gitlog_call_message <- system2("git",
                                   args = c('--git-dir',
                                            git_repo_path,
                                            'log',
#                                            '--no-merges',
#                                            'master',
                                            perceval_flags,
                                            '--all',
                                            '>',
                                            gitlog_path),
                                   stdout = TRUE,
                                   stderr = FALSE)
  }

  # Parsed JSON output.
  perceval_output <- system2(perceval_path,
                             args = c('git', '--git-log',gitlog_path,git_uri,'--json-line'),
                             stdout = TRUE,
                             stderr = FALSE)

  perceval_parsed <- data.table(jsonlite::stream_in(textConnection(perceval_output),verbose = FALSE))

  # Parse timestamps and convert to UTC
  perceval_parsed$data.AuthorDate <- as.POSIXct(perceval_parsed$data.AuthorDate,
                                                format = "%a %b %d %H:%M:%S %Y %z", tz = "UTC")
  perceval_parsed$data.CommitDate <- as.POSIXct(perceval_parsed$data.CommitDate,
                                                format = "%a %b %d %H:%M:%S %Y %z", tz = "UTC")

  # APR very first commit is a weird single case of commit without files. We filter them here.
  is_commit_with_files <- !!sapply(perceval_parsed$data.files,length)
  perceval_parsed <- perceval_parsed[is_commit_with_files]
  # Column data.files is a data.table. Unlist, so perceval_parsed is a table instead of a table of tables.
  perceval_parsed <- perceval_parsed[, .(file=unlist(data.files[[1]]$file),
                                         added=unlist(data.files[[1]]$added),
                                         removed=unlist(data.files[[1]]$removed)),, by = list(data.Author,
                                                                                       data.AuthorDate,
                                                                                       data.commit,
                                                                                       data.Commit,
                                                                                       data.CommitDate,
                                                                                       data.message)]
  # Parsing gitlog can take awhile, save if a path is provided
  if(!is.na(save_path)){
    saveRDS(perceval_parsed,save_path)
  }
  return(perceval_parsed)
}
#' Transform parsed git repo into an edgelist
#'
#' @param project_git A parsed git project by \code{parse_gitlog}.
#' @param mode The network of interest: author-file, commit-file, or author-comitter
#' @export
#' @family edgelists
parse_gitlog_network <- function(project_git, mode = c("author","commit",'author-committer')){
  data.Author <- data.AuthorDate <- data.commit <- data.Commit <- data.CommitDate <- added <- removed <- NULL # due to NSE notes in R CMD check
  # Check user did not specify a mode that does not exist
  mode <- match.arg(mode)
  # Select and rename relevant columns. Key = commit_hash.
  project_git <- project_git[,.(author=data.Author,
                        author_date=data.AuthorDate,
                        commit_hash=data.commit,
                        committer=data.Commit,
                        committer_date = data.CommitDate,
                        file,added,removed)]
  if(mode == "author"){
    # Select relevant columns for nodes
    git_nodes <- c(unique(project_git$author),unique(project_git$file))
    # Select relevant columns for edgelist, grouping repeated rows as the edgelist weights
    git_edgelist <- project_git[,.(weight=.N),by=c("author","file")]
    # Color nodes authors black, and files yellow
    git_nodes <- data.table(name=git_nodes,color=ifelse(git_nodes %in% git_edgelist$author,
                                                        "black",
                                                        "#f4dbb5"))
    # bipartite graph
    git_nodes$type <- ifelse(git_nodes$name %in% git_edgelist$author,
                              TRUE,
                              FALSE)
  }else if(mode == "commit"){
    # Select relevant columns for nodes
    git_nodes <- c(unique(project_git$commit_hash),unique(project_git$file))
    # Select relevant columns for edgelist, grouping repeated rows as the edgelist weights
    git_edgelist <- project_git[,.(weight=.N),by=c("commit_hash","file")]
    # Color authors black, and commits green and files yellow
    git_nodes <- data.table(name=git_nodes,color=ifelse(git_nodes %in% git_edgelist$commit_hash,
                                                          "#afe569",
                                                          "#f4dbb5"))
    # This undirected graph is also bipartite
    git_nodes$type <-  ifelse(git_nodes$name %in% git_edgelist$commit_hash,
                                           TRUE,
                                           FALSE)
  }else if(mode == "author-committer"){
    # Select relevant columns for nodes
    git_nodes <- unique(c(project_git$author,project_git$committer))
    # Select relevant columns for edgelist, grouping repeated rows as the edgelist weights
    git_edgelist <- project_git[,.(weight=.N),by=c("author","committer")]
    # Color authors who appear at least once under comitter as gray. Author only roles are black as usual.
    git_nodes <- data.table(name=git_nodes,color=ifelse(git_nodes %in% git_edgelist$committer,
                                                        "#bed7be",
                                                        "black"))
    # This undirected graph is also bipartite
    git_nodes$type <-  ifelse(git_nodes$name %in% git_edgelist$author,
                              TRUE,
                              FALSE)
  }
  git_network <- list()
  git_network[["nodes"]] <- git_nodes
  git_network[["edgelist"]] <- git_edgelist
  return(git_network)

}
#' Transform parsed git repo commit messages id and files into an edgelist
#'
#' @param project_git A parsed git project by \code{parse_gitlog}.
#' @param commit_message_id_regex the regex to extract the id from the commit message
#' @export
#' @family edgelists
parse_commit_message_id_network <- function(project_git, commit_message_id_regex){
  commit_message_id <- NULL # due to NSE notes in R CMD check
  # Extract the id according to the parameter regex
  project_git$commit_message_id <- data.table(stringi::stri_match_first_regex(project_git$data.message,
                                                                 pattern = commit_message_id_regex))

  # Keep only the edges which contain the commit message id

  project_git <- project_git[!is.na(commit_message_id),.(commit_message_id,
                                                         file)]
  # Select relevant columns for nodes
  git_nodes <- c(unique(project_git$commit_message_id),unique(project_git$file))
  # Select relevant columns for edgelist, grouping repeated rows as the edgelist weights
  git_edgelist <- project_git[,.(weight=.N),by=c("commit_message_id","file")]
  # Color nodes commit_message_id dark blue, and files yellow
  git_nodes <- data.table(name=git_nodes,color=ifelse(git_nodes %in% git_edgelist$commit_message_id,
                                                        "#0052cc",
                                                        "#f4dbb5"))
  # bipartite graph
  git_nodes$type <- ifelse(git_nodes$name %in% git_edgelist$commit_message_id,
                           TRUE,
                           FALSE)

  commit_message_id_network <- list()
  commit_message_id_network[["nodes"]] <- git_nodes
  commit_message_id_network[["edgelist"]] <- git_edgelist
  return(commit_message_id_network)

}
#' Parse mbox from Perceval
#'
#' @param perceval_path path to perceval binary
#' @param mbox_path path to mbox archive file (ends in .mbox)
#' @export
#' @family parsers
parse_mbox <- function(perceval_path,mbox_path){
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  perceval_path <- path.expand(perceval_path)
  mbox_path <- path.expand(mbox_path)
  # Remove ".mbox"
  mbox_uri <- stri_replace_last(mbox_path,replacement="",regex=".mbox")
  # Use percerval to parse mbox_path. --json line is required to be parsed by jsonlite::fromJSON.
  perceval_output <- system2(perceval_path,
                             args = c('mbox',mbox_uri,mbox_path,'--json-line'),
                             stdout = TRUE,
                             stderr = FALSE)
  # Parsed JSON output as a data.table.
  perceval_parsed <- data.table(jsonlite::stream_in(textConnection(perceval_output),verbose=FALSE))
  # Parse timestamps and convert to UTC
  perceval_parsed$data.Date <- as.POSIXct(perceval_parsed$data.Date,
                                                format = "%a, %d %b %Y %H:%M:%S %z", tz = "UTC")
  return(perceval_parsed)
}
#' Transform parsed mbox into a network
#'
#' @param project_mbox A parsed mbox by \code{parse_mbox}.
#' @export
#' @family edgelists
parse_mbox_network <- function(project_mbox){
  data.From <- data.Subject <- data.Date <- NULL # due to NSE notes in R CMD check
  # Obtain the relevant columns - Author, E-mail Thread, and Timestamp
  project_mbox <- project_mbox[,.(author=data.From,thread=data.Subject,date=data.Date)]
  # Select relevant columns for nodes
  mbox_nodes <- c(unique(project_mbox$author),unique(project_mbox$thread))
  # Select relevant columns for edgelist, grouping repeated rows as the edgelist weights
  mbox_edgelist <- project_mbox[,.(weight=.N),by=c("author","thread")]
  # Color authors black, and e-mail threads lightblue
  mbox_nodes <- data.table(name=mbox_nodes,color=ifelse(mbox_nodes %in% mbox_edgelist$author,
                                                      "black",
                                                      "lightblue"))
  # bipartite graph
  mbox_nodes$type <- ifelse(mbox_nodes$name %in% mbox_edgelist$author,
                           TRUE,
                           FALSE)
  # Return the parsed JSON output as nodes and edgelist.
  mbox_network <- list()
  mbox_network[["nodes"]] <- mbox_nodes
  mbox_network[["edgelist"]] <- mbox_edgelist
  return(mbox_network)
}
#' Parse dependencies from Depends
#'
#' @param depends_jar_path path to depends jar
#' @param git_repo_path path to git repo (ends in .git)
#' @param language the language of the .git repo (accepts cpp, java, ruby, python, pom)
#' @export
#' @family parsers
parse_dependencies <- function(depends_jar_path,git_repo_path,language){
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  depends_jar_path <- path.expand(depends_jar_path)
  git_repo_path <- path.expand(git_repo_path)
  # Remove ".git"
  folder_path <- stri_replace_last(git_repo_path,replacement="",regex=".git")
  project_name <- stri_split_regex(folder_path,pattern="/")[[1]]
  project_name <- project_name[length(project_name)-1]
  # Use Depends to parse the code folder.
  system2("java",
                             args = c("-jar",depends_jar_path,
                                      language,folder_path,
                                      project_name,'--dir=/tmp/',
                                      '--auto-include',
                                      '--granularity=file', '--namepattern=/',
                                      '--format=json'),
                             stdout = FALSE,
                             stderr = FALSE)
  # Construct /tmp/ file path
  output_path <- stri_c("/tmp/",project_name,".json")
  # Parsed JSON output.
  depends_parsed <- jsonlite::read_json(output_path)
  # The JSON has two main parts. The first is a vector of all file names.
  file_names <- unlist(depends_parsed[["variables"]])
  # /Users/user/git_repos/APR/xml/apr_xml_xmllite.c => "xml/apr_xml_xmllite.c"
  file_names <- stri_replace_first(file_names,replacement="",regex=folder_path)
  # The second part is the dependencies itself, which refer to the file name indices.
  dependencies <- depends_parsed[["cells"]]
  # The types of dependencies is a list of lists. First we unlist the various types.
  dependencies_types <- rbindlist(lapply(dependencies,
                                  function(x) as.data.table(x$values)),
                           fill=TRUE)
  # Fixes column types to numeric, and replace NAs by 0s, as an NA means 0 dependencies.
  dependencies_types <- data.table(sapply(dependencies_types,as.numeric))
  dependencies_types[is.na(dependencies_types)] <- 0
  # Then we unlist the src and dest files.
  dependencies_files <- rbindlist(lapply(dependencies,
                                         function(x) as.data.table(x[c("src","dest")])),
                                  fill=TRUE)
  # And finally we combine them
  depends_parsed <- cbind(dependencies_files,dependencies_types)
  # We use the file_names to re-label the files for further analysis
  # Note the +1: The json assumes a file index starts at 0. R index starts 1, hence the + 1.
  depends_parsed$src <- file_names[depends_parsed$src + 1]
  depends_parsed$dest <- file_names[depends_parsed$dest + 1]

  return(depends_parsed)
}
#' Transform parsed dependencies into a network
#'
#' @param depends_parsed A parsed mbox by \code{parse_dependencies}.
#' @param weight_types The weight types as defined in Depends.
#'
#' @export
#' @family edgelists
parse_dependencies_network <- function(depends_parsed,weight_types=NA){
  src <- dest <- weight <- NULL # due to NSE notes in R CMD check
  # Can only include types user wants if Depends found them at least once on codebase
  weight_types <- intersect(names(depends_parsed)[3:ncol(depends_parsed)],weight_types)
  dependency_edgelist <- depends_parsed[,.(src,dest)]
  if(any(is.na(weight_types))){
    dependency_edgelist$weight <- rowSums(depends_parsed[,3:ncol(depends_parsed),with=FALSE])
  }else{
    dependency_edgelist$weight <- rowSums(depends_parsed[,weight_types,with=FALSE])
  }
  # Remove dependencies not chosen by user
  dependency_edgelist <- dependency_edgelist[weight != 0]
  # Select relevant columns for nodes
  dependency_nodes <- unique(c(dependency_edgelist$src,dependency_edgelist$dest))
  # Color files yellow
  dependency_nodes <- data.table(name=dependency_nodes,color="#f4dbb5")
  # Return the parsed JSON output as nodes and edgelist.
  file_network <- list()
  file_network[["nodes"]] <- dependency_nodes
  file_network[["edgelist"]] <- dependency_edgelist
  return(file_network)
}
#' Parse NVD Feed CVEs, descriptions and CWE ids
#'
#' @param nvdfeed_folder_path Folderpath for nvd feed files
#' under schema 1.1 (e.g. nvdcve-1.1-2018.json)
#' @export
#' @family parsers
parse_nvdfeed <- function(nvdfeed_folder_path){
  folder_path <- path.expand(nvdfeed_folder_path)
  all_files_path <- list.files(folder_path,full.names = TRUE)

  parse_single_feed <- function(nvd_feed_json){
    all_cves <- nvd_feed_json[["CVE_Items"]]
    n_cves <- nvd_feed_json[["CVE_data_numberOfCVEs"]]
    cve_list <- vector(mode = "list", length = n_cves)
    for (i in 1:as.integer(n_cves)){
      cve <- all_cves[[i]][["cve"]]
      cve_id <- cve[["CVE_data_meta"]][["ID"]]
      cwe_metadata <- cve[["problemtype"]][["problemtype_data"]][[1]][["description"]]
      # can be missing if CVE is rejected. See CVE-1999-0020 as example on 2002 feed file.
      if(length(cwe_metadata) > 0){
        cwe_id <- cwe_metadata[[1]][["value"]]
      }else{
        cwe_id <- NA
      }
      cve_description <- cve[["description"]][["description_data"]][[1]][["value"]]
      cve_list[[i]] <- data.table(cve_id,cwe_id,cve_description)
    }
    return(rbindlist(cve_list))
  }
  n_nvdfeeds <- length(all_files_path)
  cve_list <- vector(mode = "list", length = n_nvdfeeds)
  for(i in 1:n_nvdfeeds){
    nvd_json <- jsonlite::read_json(all_files_path[i])
    cve_list[[i]] <- parse_single_feed(nvd_json)
  }
  return(rbindlist(cve_list))
}
#' Transform parsed cveid and nvdfeed into a network
#'
#' @param project_cve A parsed cve edgelist by \code{\link{parse_commit_message_id_network}}.
#' @param nvd_feed  Parsed  nvdfeed by \code{\link{parse_nvdfeed}}.
#' @export
#' @family edgelists
parse_cve_cwe_file_network <- function(project_cve,nvd_feed){
  commit_message_id <- cwe_id <- name <- color <- src <- dest <- weight <- NULL # due to NSE notes in R CMD check

  cve_nodes <- project_cve[["nodes"]]
  cve_edgelist <- project_cve[["edgelist"]]
  # Find the edges from CVE ids to CWE ids
  cwe_edgelist <- merge(
    cve_edgelist,
    nvd_feed,
    by.x="commit_message_id",
    by.y = "cve_id",
    all.x = TRUE)[,.(commit_message_id,cwe_id)]
  # Edges from CVE ids without a matching CWE should be removed
  cwe_edgelist <- cwe_edgelist[!is.na(cwe_id)]
  # Add all new CWE IDs to the list of nodes with a different color
  # Type is dropped, as graph viz tools can't distinguish between 3 types of nodes
  cve_nodes <- cve_nodes[,.(name,color)]
  cwe_nodes <- data.table(name=unique(cwe_edgelist$cwe_id),
                          color="#D44942")
  # Set Union Nodes
  cve_cwe_file_nodes <- rbind(cve_nodes,cwe_nodes)
  # Network will be 3 modal, rename columns to avoid confusion
  colnames(cve_edgelist) <- c("src","dest","weight")
  colnames(cwe_edgelist) <- c("src","dest")
  # For each cve id, only 1 edge is added, hence weight is always 1
  cwe_edgelist$weight <- rep(1,nrow(cwe_edgelist))
  # Set union the cve and cwe edgelists
  cve_cwe_file_edgelist <- rbind(cve_edgelist,cwe_edgelist)
  # Return the set union as nodes and edgelist.
  cve_cwe_file_network <- list()
  cve_cwe_file_network[["nodes"]] <- cve_cwe_file_nodes
  cve_cwe_file_network[["edgelist"]] <- cve_cwe_file_edgelist
  return(cve_cwe_file_network)
}
#' Parse Java Code Refactorings
#'
#' @param rminer_path The path to RMiner binary.
#'  See \url{https://github.com/tsantalis/RefactoringMiner#running-refactoringminer-from-the-command-line}
#' @param git_repo_path path to git repo (ends in .git)
#' @param start_commit the start commit hash
#' @param end_commit the end commit hash
#' @export
#' @references Nikolaos Tsantalis, Matin Mansouri, Laleh Eshkevari,
#' Davood Mazinanian, and Danny Dig, "Accurate and Efficient Refactoring
#' Detection in Commit History," 40th
#' International Conference on Software Engineering (ICSE 2018),
#' Gothenburg, Sweden, May 27 - June 3, 2018.
parse_java_code_refactoring_json <- function(rminer_path,git_repo_path,start_commit,end_commit){
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  rminer_path <- path.expand(rminer_path)
  git_repo_path <- path.expand(git_repo_path)
  # Remove ".git"
  git_uri <- stri_replace_last(git_repo_path,replacement="",regex=".git")
  # Use percerval to parse mbox_path. --json line is required to be parsed by jsonlite::fromJSON.
  rminer_output <- system2(rminer_path,
                             args = c('-bc',git_uri,start_commit,end_commit),
                             stdout = TRUE,
                             stderr = FALSE)
  # Parsed JSON output as a data.table.
  rminer_parsed <- jsonlite::parse_json(rminer_output)
  return(rminer_parsed)
}
#' Parse File Line Metrics
#'
#' @param scc_path The path to scc binary.
#'  See \url{https://github.com/boyter/scc}
#' @param git_repo_path path to git repo (ends in .git)
#' @export
parse_line_metrics <- function(scc_path,git_repo_path){
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  scc_path <- path.expand(scc_path)
  git_repo_path <- path.expand(git_repo_path)
  # Remove ".git"
  folder_path <- stri_replace_last(git_repo_path,replacement="",regex=".git")
  # Use Depends to parse the code folder.
  stdout <- system2(
    scc_path,
    args = c(folder_path, '--by-file','--format','csv'),
    stdout = TRUE,
    stderr = FALSE
  )
  line_metrics <- fread(stri_c(stdout,collapse = "\n"))
  # /Users/user/git_repos/APR/xml/apr_xml_xmllite.c => "xml/apr_xml_xmllite.c"
  line_metrics$Location <- stri_replace_first(line_metrics$Location,
                                              replacement="",
                                              regex=folder_path)
  return(line_metrics)
}
#' Parse File Line Type
#'
#' @param utags_path The path to scc binary.
#'  See \url{https://github.com/boyter/scc}
#' @param git_repo_path path to git repo (ends in .git)
#' @export
parse_line_type <- function(utags_path,git_repo_path){
  # Expand paths (e.g. "~/Desktop" => "/Users/someuser/Desktop")
  utags_path <- path.expand(utags_path)
  git_repo_path <- path.expand(git_repo_path)
  # Remove ".git"
  folder_path <- stri_replace_last(git_repo_path,replacement="",regex=".git")
  # Use Depends to parse the code folder.
  stdout <- system2(
    utags_path,
    args = c('-f','-','-x','-R',folder_path),
    stdout = TRUE,
    stderr = FALSE
  )
  line_types <- fread(stri_c(stdout,collapse = "\n"),sep="",
                      strip.white=TRUE,
                      header=FALSE)
  line_types <- rbindlist(lapply(stri_match_all(stdout,regex="(\\w+)[\\s]+(\\w+)[\\s]+(\\d+)[\\s]+(\\S+)[\\s]+(.+)",simplify = TRUE),data.table))
  colnames(line_types) <- c("raw_utag","token","line_type","line_number","file_path","line_content")

  # /Users/user/git_repos/APR/xml/apr_xml_xmllite.c => "xml/apr_xml_xmllite.c"
  line_types$file_path <- stri_replace_first(line_types$file_path,
                                              replacement="",
                                              regex=folder_path)
  return(line_types)
}
#' Filter commit files by extension
#'
#' Filters a data.table containing filepaths using the specified extensions
#'
#' @param dt_file any data.table containing filepaths
#' @param extension a character vector of extensions (e.g. c(py,java)) to *keep*
#' in the table
#' @param file_column_name a string indicating the column name which contains filepaths
#' @return a data.table which contains only filepaths with the specified extensions
#' @export
#' @family {filters}
#' @seealso \code{\link{parse_gitlog}} and \code{\link{parse_dependencies}} to create dt_file
filter_by_file_extension <- function(dt_file,extension,file_column_name){
  file_extension_re <- stri_c('[.](',stri_c(extension,collapse="|"),')$')
  is_file_with_extension <- stri_detect_regex(dt_file[[file_column_name]],file_extension_re)
  return(dt_file[is_file_with_extension])
}
#' Filter by filepath substring
#'
#' Filters a data.table with filepaths using the specified substring (e.g. remove
#' all filepaths which contain the word 'test' anywhere in it)
#'
#' @param dt_file any data.table containing filepaths
#' @param substring a character vector of substrings (e.g. c(py,java)) we wish to *filter*
#' @param file_column_name a string indicating the column name which contains filepaths
#' @return a data.table which contains does *not* contain filepaths with the specified words
#' @export
#' @family filters
#' @seealso \code{\link{parse_gitlog}} and \code{\link{parse_dependencies}} to create dt_file
filter_by_filepath_substring <- function(dt_file,substring,file_column_name){
  file_contains_re <- stri_c('(',stri_c(substring,collapse="|"),')')
  is_not_filepath_with_substring <- !stri_detect_regex(dt_file[[file_column_name]],file_contains_re)
  return(dt_file[is_not_filepath_with_substring])
}
#' Filter by commit interval
#'
#' Filters a data.table by with author or commit datetime using the specified start and end commits
#'
#' @param git_log any data.table with a named column `data.AuthorDate` with datetime in POSIXct
#' @param start_commit a commit hash which indicates the start of interval (the commit must exist in `git_log`)
#' @param end_commit a commit hash which indicates the end of interval (the commit must exist in `git_log`)
#' @return a data.table which contains only commits within `start_commit` and `end_commit`
#' @export
#' @family filters
#' @seealso \code{\link{parse_gitlog}} to create git_log
filter_by_commit_interval <- function(git_log,start_commit,end_commit){
  data.AuthorDate <- NULL # due to NSE notes in R CMD check
  start_date <- get_date_from_commit_hash(git_log,start_commit)
  end_date <- get_date_from_commit_hash(git_log,end_commit)
  git_log <- git_log[data.AuthorDate >= start_date & data.AuthorDate <= end_date]
  return(git_log)
}
#' Parse the git blame message of a file
#'
#' Create a data.table with the blame data of each line of a file in a specific commit.
#'
#' @param git_repo_path git_repo_path path to git repo (ends in .git)
#' @param flags the parameters for invoking git blame (https://git-scm.com/docs/git-blame)
#' @param commit_hash a commit hash which indicates the specific version of the file (the commit must exist in `git_log`)
#' @return a data.table which contains blame commits for each line of a file and metadata of the commits.
#' @export
parse_git_blame <- function(git_repo_path,flags,commit_hash,file_path){
  # Call function git_blame to obtain the blame message into blame_file
  blame_file <- git_blame(git_repo_path,
                          flags,
                          commit_hash,
                          file_path)
 # Regex to find the commit that refers to the blame of a line
  cond<-'(?<=.)(?=[a-f0-9]{40} \\d+)'
  # Paste the content of blame_file into one line
  pasted <- paste(blame_file,collapse = '')
  # Split the pasted text on the commits that refer to the blame
  splitted <- stri_split_regex(pasted,cond)
  # contains the hash of the blame commit, the line on the original and line on the final file all together
  commit_line <- stri_match_all_regex(unlist(splitted),"^([a-f0-9]{40}) (\\d+) (\\d+)")
  # Retrieve from these characters the hash only
  commits <- unlist(lapply(commit_line, `[[`, 2))
  # Retrieve from these characters the number of line on the original files only
  line_number_of_the_line_in_the_original_file <- unlist(lapply(commit_line, `[[`, 3))
  # Retrieve from these character the number of line on the final file only
  line_number_of_the_line_in_the_final_file <- unlist(lapply(commit_line, `[[`, 4))
  # Retrieve with regex functions other metadata from the chatacters splitted on the hash.
  authors <- unlist(stri_match_all_regex(unlist(splitted), "(?<=author).*(?=author-mail)"))
  author_mails <- unlist(stri_match_all_regex(unlist(splitted), "(?<=author-mail).*(?=author-time)"))
  author_time <- unlist(stri_match_all_regex(unlist(splitted), "(?<=author-time).*(?=author-tz)"))
  committers <- unlist(stri_match_all_regex(unlist(splitted), "(?<=committer).*(?=committer-mail)"))
  committer_mails <- unlist(stri_match_all_regex(unlist(splitted), "(?<=committer-mail).*(?=committer-time)"))
  committer_time <- unlist(stri_match_all_regex(unlist(splitted), "(?<=committer-time).*(?=committer-tz)"))
  committer_tz <- unlist(stri_match_all_regex(unlist(splitted), "(?<=committer-tz).*(?=summary)"))
  summaries <- unlist(stri_match_all_regex(unlist(splitted), "(?<=summary).*(?=filename)"))
  file_names <- unlist(stri_match_all_regex(unlist(splitted), "(?<=filename).*(?=\t)"))
  lines <- unlist(stri_match_all_regex(unlist(splitted), "(?<=\t).*$"))
  # Clean the retrieved metadata from the white space on the first position
  authors <- sub('.', '', authors)
  author_mails <- sub('.', '', author_mails)
  author_time <- sub('.', '', author_time)
  committers <- sub('.', '', committers)
  committer_mails <- sub('.', '', committer_mails)
  committer_time <- sub('.', '', committer_time)
  committer_tz <- sub('.', '', committer_tz)
  summaries <- sub('.', '', summaries)
  file_names <- sub('.', '', file_names)
  # Crete a table with the metadata of the blame message
  df <- data.table(commits,line_number_of_the_line_in_the_original_file,line_number_of_the_line_in_the_final_file,
                   authors,author_mails,author_time,committers,committer_mails,committer_time,committer_tz,summaries,
                   file_names,lines)
  return(df)
}
# Various imports
utils::globalVariables(c("."))
#' @importFrom magrittr %>%
#' @importFrom stringi stri_replace_last
#' @importFrom stringi stri_replace_first
#' @importFrom stringi stri_match_all
#' @importFrom stringi stri_match_first_regex
#' @importFrom stringi stri_detect_regex
#' @importFrom stringi stri_c
#' @importFrom stringi stri_split_regex
#' @importFrom data.table data.table
#' @importFrom data.table is.data.table
#' @importFrom data.table as.data.table
#' @importFrom data.table .N
#' @importFrom data.table :=
#' @importFrom data.table rbindlist
#' @importFrom data.table setkey
#' @importFrom data.table setkeyv
#' @importFrom data.table setnames
NULL
