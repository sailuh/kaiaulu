---
title: "Download GitHub Pull Request Comments via REST API"
output: 
  html_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Download GitHub Pull Request Comments via REST API}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

# Introduction

In this vignette, the goal is to download all comments on the GitHub
Pull Requests Conversations tab. In a GitHub Pull Request, comments
written in the conversations tab are not easily retrievable by one
endpoint in chronological order. They are instead split into four
mutually exclusive endpoints. The four REST API endpoints being used are
pull requests, issue/pr comments, pull request in-line comments, and
pull request reviews.

-   Pull Requests

    -   Reviews

        -   In-Line PR Comment

    -   Pull Request Comments

## Libraries

To use the notebook, you will need to ensure you have the required R
packages installed.

```{r warning=FALSE,message=FALSE}
rm(list = ls())
require(kaiaulu)
require(data.table)
require(jsonlite)
require(knitr)
require(magrittr)
require(gt)
require(lubridate)
```

## Project Configuration File

To use the pipeline, you must specify the organization and project of
interest.

```{r warning=FALSE}
conf <- parse_config("../conf/kaiaulu.yml")
owner <- get_github_owner(conf, "project_key_1") # Has to match github organization (e.g. github.com/sailuh)
repo <- get_github_repo(conf, "project_key_1") # Has to match github repository (e.g. github.com/sailuh/perceive)

# Path you wish to save all raw data.
save_path_pull_request <- get_github_pull_request_path(conf, "project_key_1")
save_path_pr_comments <- get_github_pr_comments_path(conf, "project_key_1")
save_path_issue_or_pr_comments <- get_github_issue_or_pr_comment_path(conf, "project_key_1")
save_path_pr_reviews <- get_github_pr_review_path(conf, "project_key_1")
# Create all folder directories
#create_file_directory(conf)
```

## Create a Personal Token

GitHub limits the number of API calls per IP to only 60 attempts **every
hour** at the time this vignette was created. You can check the current
rates at [its
website](https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#rate-limiting).

If using a personal account token from a free GitHub account, the number
of API calls per hour increases to 5000 **per hour**. Therefore, it is
recommended you create a personal token by following the [GitHub
Documentation
instructions](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-personal-access-token#:~:text=Creating%20a%20token.%201%20Verify%20your%20email%20address%2C,able%20to%20see%20the%20token%20again.%20More%20items).
The process should not take more than 2 minutes.

The token should then be copied and pasted into `../.ssh/github_token`.
Both the `.ssh` folder and `github_token` file may need to be created
manually. Check for hidden folders before creating the `.ssh` folder.
The `github_token` file should not have any file extensions.

```{r Scan GitHub Token}
# your file github_token (a text file) contains the GitHub token API
token <- scan("~/.ssh/github_token",what="character",quiet=TRUE)
```

# GitHub Pull Request Comment Types

The GitHub API distinguishes conversation happening on a Pull Request page as one of four types, and provides a different endpoint API for each:

  * **Pull Request Description**: The first "comment" in a Pull Request, which is written by the author of the Pull Request when creating it.
  * **Pull Request Conversation Comment**: When using a browser to access GitHub, users can post comments on the **Conversation** tab. These comments have no association to source code. Note the Pull Request Description will not be obtained by this endpoint. 
  * **Pull Request Review**: These reviews are done when a reviewer selects the "Files Changed" tab, and subsequently uses the "Review Changes" green button in this page. The Review comment is often used in conjunction with inline source code comments. For example, several inline comments can be made, and then a Pull Request review can be posted, which groups them in the Conversation Tab. The Pull Request Review also contains the labels of "Change Requested" or "Approved" if the reviewer marked them as such. However, this information may not be present if the reviewer posted it as "Comment". Refer to the browser interface UI for its definitions.
  * **Pull Request Inline Comments**: These are comments posted on the "Files Changed" tab, by selecting a file line of code, pressing the "+" and then commenting inline. Reviewers can also hold "shift key" to highlight multiple lines of code to post a comment about them. These comments can then either be saved as a) "Add single line comment" or b) "Start review". If "Add single line comment" is chosen, then the comment is posted on its own in the "Conversation" tab. However, if "Start Review" is chosen, then the comment will not be posted until the **Pull Request Review** is posted grouping them. Comments posted as "Start Review" will have an explicit ID referencing the Pull Request Review ID. Accordingly, "Add single line comment" will not have a reference ID. Inline Comments are also unique in that the API provides the source code snippet associated to the comment for analysis.

The remainder of this notebook showcases how to obtain the four types of data using Kaiaulu. In the final section, the four endpoints are used to combine a Pull Request page from Kaiaulu to resemble the conversation tab. You can modify the Pull Request ID for Kaiaulu or any other GitHub project for analysis.  

## GitHub Pull Request Conversation Comments

Pull Request Comments not connected to a review, appear in the GitHub Pull Request Conversations tab but is retrieved by the issue comments endpoint. Using this endpoint, both issues and pull request comments are retrieved.

```{r Collect comments by pull request number}
#gh call but with date
# get the data
gh_response_issue_or_pr_comment <- github_api_project_issue_or_pr_comment_refresh(owner,repo,token,save_path_issue_or_pr_comments,verbose=TRUE)

# create directory and iterate over data
#dir.create(save_path_issue_or_pr_comments)
github_api_iterate_pages(token,gh_response_issue_or_pr_comment,
                         save_path_issue_or_pr_comments,
                         prefix="issue_or_pr_comment",
                         verbose=TRUE)
```

It is important to filter out the issue comments in this notebook. The
key to this is in the html_url of each comment, differentiated by
/issues or /pull

```{r}
pr_comments <- lapply(list.files(save_path_issue_or_pr_comments, full.names = TRUE),read_json)
pr_comments <- lapply(pr_comments, github_parse_project_issue_or_pr_comments)
pr_comments <- rbindlist(pr_comments,fill=TRUE)

#filter only pull requests using grepl
pr_comments <- pr_comments[grepl("/pull/", html_url)]

head(pr_comments,3)  %>%
  gt(auto_align = FALSE) 
```

## Pull Request Description

We may notice the first comment of the pull request is missing. The pull request description is treated as a pull request comment in the conversations tab by GitHub. However, it is not retrievable by the other comments endpoints. To get this, we must utilize the pull request endpoint to gather information on the pull request, and retrieve the body paragraph for that pull request.

```{r Collect information on pull request}
gh_response <- github_api_project_pull_request_refresh(owner, repo, token, save_path_pull_request)
github_api_iterate_pages(token, gh_response, save_path_pull_request, prefix="pull-request", verbose=TRUE)
```

```{r}
pull_requests <- lapply(list.files(save_path_pull_request,
                                     full.names = TRUE),read_json)
pull_requests <- lapply(pull_requests,
                                   github_parse_project_pull_request)
pull_requests <- rbindlist(pull_requests,fill=TRUE)

head(pull_requests,3)  %>%
  gt(auto_align = FALSE) 
```

## Pull Request Reviews

Up until now, previous comments were not associated to code review. Users can perform code reviews by adding in-line code review comments and saving them together with "Changes Requested", "Approved" or just a single comment in-line rather than grouping. The review endpoint allows analysts to see the state of the review such as requesting changes, approving, or a singular comment. With this the review has its own comment body different from the in-line code comments. More information on the fields can be seen on the function definition for `github_parse_project_pr_reviews`. 

```{r Collect Reviews from Pull Requests}
gh_response <- github_api_project_pull_request_review_refresh(owner, repo, token, save_path_pull_request, save_path_pr_reviews,verbose=TRUE)
```

```{r Parse Review Comments from Pull Requests}
pr_reviews <- lapply(list.files(save_path_pr_reviews, full.names = TRUE), read_json)
pr_reviews <- lapply(pr_reviews, github_parse_project_pull_request_reviews)
pr_reviews <- rbindlist(pr_reviews, fill = TRUE)
head(pr_reviews,3)  %>%
  gt(auto_align = FALSE) 
```

## Pull Request In-Line Code Comments

Other information we can obtain is the in-line code comments from Pull
Requests. The comments include the diff_hunk field, which is a string
that contains the in-line code reviewers may comment on the pull
request. The particular line numbers the comment is referencing is
specified by the review comment. These in-line code comments have a
matching review id number that matches the review endpoint and other
in-line code comments, therefore grouping them all together. More
information on the fields can be seen on the function definition for
`github_parse_project_pull_request_inline_comments`. These fields of data can greatly
contribute to finding and analyzing patterns in collaboration between
developers.

```{r Collect Comments from Pull Requests}
gh_response <- github_api_project_pull_request_inline_comments_refresh(owner, repo, token)
github_api_iterate_pages(token, gh_response, save_path_pr_comments, prefix="pr_comments")
```

```{r Parse Comments from Pull Requests}
inline_comments <- lapply(list.files(save_path_pr_comments, full.names = TRUE), read_json)
inline_comments <- lapply(inline_comments, github_parse_project_pull_request_inline_comments)
inline_comments <- rbindlist(inline_comments, fill = TRUE)
head(inline_comments,2)  %>%
  gt(auto_align = FALSE) 
```


# Putting All Together: Pull Request Conversations Tab

After understanding the four endpoints that make up GitHub
Conversations, we want to visualize that in the Kaiaulu. Here we gather
specified data from pull_requests, pr_comments, pr_reviews, and in-line
comments and the goal is to organize them by PR Review number and time.

```{r Tabulate Endpoints}

extract_issue_number  <- function(comment_url){
  last_element <- length(stringi::stri_split(comment_url,regex = "/")[[1]])
  issue_number <- stringi::stri_split(comment_url,regex = "/")[[1]][last_element]
  issue_number <- as.integer(stringi::stri_split(issue_number,regex="#")[[1]][1])
  return(issue_number)
}

pull_requests <- lapply(list.files(save_path_pull_request,full.names = TRUE),read_json)
pull_requests <- lapply(pull_requests, github_parse_project_pull_request)
pull_requests <- rbindlist(pull_requests,fill=TRUE)
pull_requests <- pull_requests[,.(issue_number=issue_number,html_url=html_url, created_at=created_at, body=body )]

pr_comments <- lapply(list.files(save_path_issue_or_pr_comments, full.names = TRUE), read_json)
pr_comments <- lapply(pr_comments, github_parse_project_pull_request_inline_comments)
pr_comments <- rbindlist(pr_comments, fill = TRUE)
pr_comments <- pr_comments[grepl("/pull/", html_url)]
pr_comments$issue_number <- sapply(pr_comments$html_url,extract_issue_number)
pr_comments <- pr_comments[,.(issue_number=issue_number, html_url=html_url, created_at=created_at, body=body )]

inline_comments <- lapply(list.files(save_path_pr_comments, full.names = TRUE), read_json)
inline_comments <- lapply(inline_comments, github_parse_project_pull_request_inline_comments)
inline_comments <- rbindlist(inline_comments, fill = TRUE)
inline_comments$issue_number <- sapply(inline_comments$html_url,extract_issue_number)
inline_comments <- inline_comments[,.(issue_number=issue_number, html_url=html_url, PR_review=review_id, created_at=created_at, body=body )]

pr_reviews <- lapply(list.files(save_path_pr_reviews, full.names = TRUE), read_json)
pr_reviews <- lapply(pr_reviews, github_parse_project_pull_request_reviews)
pr_reviews <- rbindlist(pr_reviews, fill = TRUE)
pr_reviews$issue_number <- sapply(pr_reviews$html_url,extract_issue_number)
pr_reviews <- pr_reviews[,.(issue_number=issue_number,html_url=html_url, PR_review=review_id, created_at=submitted_at, body=body, state=state)]

pr_endpoints <- rbind(pull_requests, pr_comments, inline_comments, pr_reviews, fill = TRUE)

#pr_endpoints[, thread_root := ifelse(is.na(PR_review), 
#                                    NA,
#                                    html_url)]

# Step 1: Add a sort key that gives priority to review summary (state not NA)
#pr_endpoints[, is_review_summary := !is.na(state)]

# Step 2: Use PR_review as a grouping variable â€” fallback to NA if no review ID
#pr_endpoints[, thread_id := fcoalesce(as.character(PR_review), html_url)]

# Step 3: Order by thread ID, then review summary (TRUE = 1, sorted before FALSE = 0), then timestamp
#pr_endpoints <- pr_endpoints[order(thread_id,
#                                   -as.integer(is_review_summary),
#                                   created_at)]

# time_value <- as.POSIXct(created, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
pr_endpoints$dates <- lubridate::ymd_hms(pr_endpoints$created_at) 
head(pr_endpoints[issue_number==325][order(dates)],100)  %>%
  gt(auto_align = FALSE) 
```
